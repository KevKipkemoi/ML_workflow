{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"Tensor flow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "train_dataset_fp = tf.keras.utils.get_file(\n",
    "    fname = os.path.basename(train_dataset_url),\n",
    "    origin = train_dataset_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Local copy of dataset: {}\".format(train_dataset_fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n5 {train_dataset_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels description\n",
    "0: iris setosa\n",
    "1: iris versicolor\n",
    "2: iris virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Labels: {}\".format(label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = tf.contrib.data.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names = column_names,\n",
    "    label_name = label_name,\n",
    "    num_epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    features['petal_length'].numpy(),\n",
    "    features['sepal_length'].numpy(),\n",
    "    c = labels.numpy(),\n",
    "    cmap = 'viridis'\n",
    ")\n",
    "\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Sepal Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_feature_vector(features, labels):\n",
    "    \"\"\"Pack features into a single array\"\"\"\n",
    "    features = tf.stack(list(features.values()), axis = 1)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack the features pairs of each (features, label) into the training dataset\n",
    "train_dataset = train_dataset.map(pack_feature_vector)\n",
    "\n",
    "# Look at the features dataset array that's now an array of shape (batch_size, num_features)\n",
    "features, labels = next(iter(train_dataset))\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape = (4,)),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits to a probability for each class\n",
    "tf.nn.softmax(predictions[:5])\n",
    "print(\"Predictions: {}\".format(tf.argmax(predictions, axis = 1)))\n",
    "print(\"Labels: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Loss Gradient Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(model, features, labels)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following implements Stochastic Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "global_step = tf.Variable(0)\n",
    "loss_value, grads = grad(model, features, labels)\n",
    "print(\"Step: {}, Initial loss: {}\".format(global_step.numpy(), loss_value.numpy()))\n",
    "optimizer.apply_gradients(zip(grads, model.trainablevariables, global_step))\n",
    "print(\"Step: {}, Loss: {}\".format(global_step.numpy(), loss(model, features, labels).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tesorflow import contrib\n",
    "tfe = contrib.eager\n",
    "\n",
    "# Keep the plotting results\n",
    "training_loss_results = []\n",
    "training_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "    \n",
    "    # Training loop with batches of 32\n",
    "    for x, y in train_dataset:\n",
    "        # Optimeize the model\n",
    "        loss_value = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value) # add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
    "    # end epoch\n",
    "    training_loss_results.append(epoch_loss_avg.result())\n",
    "    training_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch: {:03d}, Loss:{:.3f}, Accuracy: {:3%}\".format(\n",
    "            epoch,\n",
    "            epoch_loss_avg.result(),\n",
    "            epoch_accuracy.result()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
